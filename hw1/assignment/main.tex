%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% fphw Assignment
% LaTeX Template
% Version 1.0 (27/04/2019)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Class by Felipe Portales-Oliva (f.portales.oliva@gmail.com) with template 
% content and modifications by Vel (vel@LaTeXTemplates.com)
%
% Template (this file) License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	12pt, % Default font size, values between 10pt-12pt are allowed
	%letterpaper, % Uncomment for US letter paper size
	%spanish, % Uncomment for Spanish
]{fphw}

% Template-specific packages
\usepackage{lmodern}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{epstopdf}
\usepackage[table]{xcolor}
\usepackage{matlab}
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{mathpazo} % Use the Palatino font

\usepackage{graphicx} % Required for including images

\usepackage{booktabs} % Required for better horizontal rules in tables

\usepackage{listings} % Required for insertion of code

\usepackage{enumerate} % To modify the enumerate environment


\usepackage{tikzit}
\usetikzlibrary{automata, calc, positioning}
\input{style.tikzstyles}

\usepackage{amsmath}

%\usepackage[colorlinks = true, linkcolor = blue]{hyperref}
%\renewcommand{\equationautorefname}{equazione}

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Homework 1} % Assignment title

\author{Andrea Ruglioni, Giulia Monchietto, Edoardo Venturini} % Student name

\date{15 Novembre 2022} % Due date

\institute{Politecnico di Torino} % Institute or school name

\class{Processi stocastici} % Course or class name

\professor{Enrico Bibbona} % Professor or teacher in charge of the assignment

\group{Giulio Merlo, Emma Matteja}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the assignment title, created automatically using the information in the custom commands above

%----------------------------------------------------------------------------------------
%	ASSIGNMENT CONTENT
%----------------------------------------------------------------------------------------
\section*{Esercizio 1}
\begin{problem}
	\smallskip
	Esibire (se esiste, altrimenti specificare che non esiste e motivare il perchè)
	\begin{enumerate}[(\itshape a\normalfont)]
		\item una DTMC con almeno 3 stati tale per cui tutte le righe della
		matrice di transizione abbiano almeno due elementi strettamente positivi e tale che ammetta una distribuzione stazionaria,
		ma non una distribuzione limite.
		\item un Processo di Poisson non omogeneo con intensità pari a $\lambda(x) = 2\sin x$. Per "esibire" il processo qui si intende spiegare come fare
		a costruirlo in maniera esplicita
		\item un Processo di Poisson non omogeneo con intensità pari a $\lambda(x) = 2\log (x+2)$. Per "esibire" il processo qui si intende spiegare come fare
		a costruirlo in maniera esplicita
		\item una DTMC per cui esistono esattamente tre distribuzioni stazionarie
		\item una DTMC per cui esistono infinite distribuzioni stazionarie,
		ma nessuna distribuzione limite		
	\end{enumerate}
	\smallskip
\end{problem}

\subsection*{Soluzione}
\begin{enumerate}[(\itshape a\normalfont)]
	\item Definiamo una DTMC con la seguente matrice di transizione P, la quale possiede esattamente due elementi positivi per ogni riga:
	\begin{equation*}
	P = \begin{pmatrix}
		0 & 0.5 & 0 & 0.5\\
		0.5 & 0 & 0.5 & 0\\
		0 & 0.5 & 0 & 0.5\\
		0.5 & 0 & 0.5 & 0
		\end{pmatrix}.
	\end{equation*}
	La DTMC è rappresentabile graficamente come:
	\ctikzfig{fig5}

	Osserviamo che la catena è irriducibile, poichè tutti gli stati sono comunicanti, ed è inoltre finita, perciò esiste ed è unica la distribuzione stazionaria.\\
	Una catena ammette una distribuzione limite se esiste una distribuzione $\pi$ tale che, 
	qualsiasi sia la distribuzione iniziale $\alpha = (\alpha_i)_{i \in S}$, $\forall x \in S$, dove $S$ è lo spazio degli stati, vale:
	\begin{equation*}
		\lim_{n \to \infty}  \mathbb{P} (X_n = x) = \pi (x)
	\end{equation*}
	Osserviamo però che la catena è periodica. Infatti ogni stato, a partire dall'istante $t$ in cui viene visitato la prima volta, 
	potrà essere nuovamente visitato solamente negli istanti $t' = t + 2k$ per $k\in \mathbb{N}$. Segue che non può esistere una distribuzione limite, 
	dato che, partendo da uno tra gli stati $1$ e $3$, negli istanti $t' = 2k$ per $k \in \mathbb{N}$ la catena si potrà trovare solamente negli stati $1$ e $3$, mentre negli
	istanti $t' = 2k + 1$ la DTMC si potrà trovare solamente nello stato $2$ o nello stato $4$.
	Quindi il comportamento limite della catena dipende dalla distribuzione iniziale $\alpha$.
	\item Per costruire un Processo di Poisson non omogeneo ci riferiamo al seguente teorema:\\
	\\
	\null\quad \textit{Sia $N(t)$ un processo di Poisson con parametro 1, e sia $\lambda(t)$ una funzione\\
	\null\quad non negativa del tempo. Allora
	\begin{equation*}
		\quad M(t) = N(\int_0^t \lambda(\mu)d\mu)
	\end{equation*}
	\null\quad è un Processo di Poisson non omogeneo con intensità $\lambda(t)$}.\\
	\\
	In questo caso, la funzione $2\sin(x)$ non è non negativa, quindi non è possibile costruire un Processo di Poisson con tale intensità.
	\item Riferendoci al teorema precedente, presa $f(t) = 2t\log(t+2) - 2t = \int_0^t 2\log(\mu + 2)d\mu$, 
	si ha che $M(t) = N(f(t))$ è il processo di Poisson desiderato.
	\item Una distribuzione è stazionaria se e solo se può essere espressa come combinazione convessa di distribuzioni stazionarie estremali.\\
	Perciò, se per assurdo esistesse più di una distribuzione stazionaria, ciò implicherebbe l'esistenza di infinite distribuzioni stazionarie ottenibili come combinazione convessa delle precedenti,
	contraddicendo l'ipotesi iniziale dell'esistenza di più di una distribuzione stazionaria.
	In conclusione, non può esistere una DTMC con esattamente $3$ distribuzioni stazionarie.
	\item Consideriamo la seguente DTMC con relativa matrice di transizione P definita come:
	\begin{equation*}
		P = \begin{pmatrix}
			0 & 1 & 0 & 0\\
			1 & 0 & 0 & 0\\
			0 & 0 & 0 & 1\\
			0 & 0 & 1 & 0
		\end{pmatrix}
	\end{equation*}
	La DTMC possiede la seguente rappresentazione grafica:
	\ctikzfig{fig1}
	Le distribuzioni stazionarie relative alla DTMC sono costituite da tutti i possibili vettori $\pi \in \mathbb{R}_+ ^4$ tali da soddisfare:
	\begin{align*}
	\pi &= \pi P & \sum_{i = 1}^{4} \pi_i &= 1 
	\end{align*}
	A partire da quest'ultima equazione si ottiene:
	\begin{equation*}
		\begin{cases} 
			\pi_1 = \pi_2\\
			\pi_3 = \pi_4
		\end{cases}
	\end{equation*}
	Osservo che le seguenti sono due possibili distribuzioni stazionarie
	\begin{align*}
		\pi &= \begin{pmatrix}
			0.5 & 0.5 & 0 & 0 
		\end{pmatrix} & 
		\pi' &= \begin{pmatrix}
			0 & 0 & 0.5 & 0.5 
		\end{pmatrix}
	\end{align*}
	Di conseguenza è possibile ottenere infinite distribuzioni stazionarie
	esprimibili come combinazione convessa di $\pi$ e $\pi'$ come $\forall \lambda \in (0,1)$:
	\begin{equation*}
		\lambda \pi' + (1-\lambda ) \pi 
	\end{equation*}
	Per quanto riguarda la distribuzione limite, essa non esiste poichè per qualunque classe ricorrente
	in cui la catena venga inizializzata, la DTMC rimarrà in quest'ultima classe con probabilità $1$ ad ogni tempo $t$.
	Dato che esistono due classi ricorrenti,non può esistere una distribuzione limite indipendente dallo stato di partenza.


\end{enumerate}

\newpage
\section*{Esercizio 2}
\begin{problem}
	\smallskip
	Sia $(X_n)_{n \ge 0}$ una catena di Markov sullo spazio $S$. Si provi che:
	\begin{enumerate}[(\itshape a\normalfont)]
		\item Ogni classe di comunicazione $E$  è massimale, 
		ovvero se $E \subset F$ per una classe di comunicazione F, allora $E = F$.
		\item Se $E_1, E_2$ sono due classi comunicanti per la catena e
		$E_1 \cap E_2 \ne \emptyset$, allora $E_1 = E_2$
	\end{enumerate}
	\smallskip
\end{problem}
\medskip
\subsection*{Soluzione}
	\begin{enumerate}[(\itshape a\normalfont)]
		\item Dato che F è per ipotesi una classe di comunicazione, vale che $\forall i, j \in F\text{, }i\longleftrightarrow j$.
		Quindi in particolare:
		\begin{equation*}
			\forall i \in F ~ \exists j \in E \subset F : j \to i.
		\end{equation*}
		Ma essendo E una classe di comunicazione anch'essa, se $j\longrightarrow i$ allora $i \in E$.
		Di conseguenza $F\subset E$, e dato che per ipotesi $E\subset F$, ciò implica $E=F$.
		\item $E_1$ è una classe di comunicazione per cui
		\begin{equation*}
			\forall i \in E_1 ~ \exists j \in E_1 \cap E_2 \ne \emptyset : i \leftrightarrow j.
		\end{equation*}
		Poiché $E_2$ è anch'essa una classe di comunicazione, vale anche che $j \leftrightarrow k ~ \forall k \in E_2 \setminus E_1$.
		Essendo la comunicazione una relazione di equivalenza, vale la proprietà transitiva la quale implica che $i \leftrightarrow k$.
		Ne consegue che $i \in E_2$ e $k \in E_1$, perciò $E_1 \subset E_2$ ed $E_2 \subset E_1$, concludiamo che $E_1 = E_2$.
	\end{enumerate}

%----------------------------------------------------------------------------------------

\newpage
\section*{Esercizio 3}

\begin{problem}
	\smallskip
	Mary is in prison and has 3 dollars; she can get out on bail if he
	has 8 dollars. A guard agrees to make a series of bets with her.
	If Mary bets A dollars, she wins A dollars with probability 0.4 and loses A dollars with probability 0.6.
	Find the probability that she wins 8 dollars before losing all of his money if
	\medskip
	\begin{enumerate}[(\itshape a\normalfont)]
		\item she bets 1 dollar each time (timid strategy).
		\item she bets, each time, as much as possible but not more than necessary to bring his fortune up to 8 dollars (bold strategy).
	\end{enumerate}
	\smallskip
	Which strategy gives Mary the better chance of getting out of jail?
	\smallskip
\end{problem}

%------------------------------------------------

\subsection*{Soluzione}

\begin{enumerate}[(\itshape a\normalfont)]
	\item La strategia timida definisce una DTMC le cui probabilità di transizione sono date da:
		\begin{equation*}
			\begin{aligned}
				&\mathbb{P}(0, 0) = 1,	\\
				&\mathbb{P}(i, i+1) = p = 0.4	\qquad &i = 1, \dots, 7,	\\
				&\mathbb{P}(i, i-1) = q = 1-p = 0.6	\qquad &i = 1, \dots, 7,	\\
				&\mathbb{P}(8, 8) = 1.
			\end{aligned}
		\end{equation*}
		Mentre il rispettivo grafo è dato da
		\ctikzfig{fig4}
		Ponendoci nel caso generale, supponiamo di partire con $0 \leq n \leq 8$ dollari.
		Sia $U_n$ l'evento "uscire dalla prigione partendo con n dollari", $V$ l'evento "Mary vince una scommessa" e $P = \overline{V}$ "Mary perde una scommessa".
		Allora, per la formula delle probabilità assoluta si ha che
		\begin{equation} \label{eq:es3_1}
			\begin{aligned}
				\mathbb{P}(U_n) &= \mathbb{P}(U_n | V)\mathbb{P}(V) + \mathbb{P}(U_n | P)\mathbb{P}(P) \\
					&= \mathbb{P}(U_n | V)p + \mathbb{P}(U_n | P)q \\
					&= \mathbb{P}(U_{n+1})p + \mathbb{P}(U_{n-1}) q.
			\end{aligned}
		\end{equation}
		L'ultima uguaglianza segue dal fatto che, sapendo di aver vinto una scommessa, avrò $n+1$ dollari, per cui $\mathbb{P}(U_n | V) = \mathbb{P}(U_{n+1})$.
		Possiamo effettuare un ragionamento simile nel caso in cui Mary perda una scommessa.
		Definiamo ora per semplicità di notazione $u_n = \mathbb{P}(U_n)$.
		Otteniamo così l'equazione ricorsiva con condizioni al contorno su $u_0, u_8$:
		\begin{equation*}
			\begin{cases}
				u_n = u_{n+1}p + u_{n-1}q \qquad n = 1, \dots, 7, \\
				u_0 = 0, \\
				u_8 = 1.
			\end{cases}
		\end{equation*}
		Possiamo risolvere tale equazione ricorsiva lineare del secondo ordine risolvendo prima l'equazione associata
		\begin{equation*}
			px^2 - x + q = 0.
		\end{equation*}
		Da cui si ricavano le soluzioni
		\begin{align*}
			x_1 &= \frac{1 + \sqrt{1 - 4pq}}{2p}, & x_2 &= \frac{1 - \sqrt{1 - 4pq}}{2p}.
		\end{align*}
		Ponendo $p = 0.4$, e quindi $q = 0.6$, si ottiene $x_1 = \frac{3}{2}$, $x_2 = 1$.
		Dunque si ha che
		\begin{equation*}
			u_n = Ax_1^n + Bu_2^n = A\left( \frac{3}{2} \right)^n + B,
		\end{equation*}
		dove $A$ e $B$ sono costanti che si ottengono applicando le condizioni al contorno
		\begin{equation*}
			\begin{gathered}
				u_0 = 0 = A + B \Rightarrow  B = -A, \\
				u_8 = 1 = A\left( \left( \frac{3}{2} \right)^8 - 1 \right) \Rightarrow A = - \frac{1}{\left( \frac{3}{2} \right)^8 - 1}.
			\end{gathered}
		\end{equation*}
		In conclusione, vale che
		\begin{equation*}
			u_n = \frac{\left( \frac{3}{2} \right)^n - 1}{\left( \frac{3}{2} \right)^8 - 1},
		\end{equation*}
		ed in particolare, ponendo $n = 3$, si ottiene che $u_3 \approx 0.0964$.
	
	\item La strategia audace consiste invece nel scommettere ad ogni passo una quantità data da $min\{n, 8-n\}$.
		In questo modo, l'\autoref{eq:es3_1} diventa:
		\begin{equation*}
			u_n = u_{min\{2n, 8\}}p + u_{max\{0, 2n-8\}}q.
		\end{equation*}
		Partendo dal valore $n = 3$, e ricordando le condizioni iniziali $u_0 = 0, u_8 = 1$, si ricavano le seguenti equazioni:
		\begin{equation*}
			\begin{aligned}
				u_3 &= u_6p + u_0q = u_6p,	\\
				u_6 &= u_8p + u_4q = p + u_4q,	\\
				u_4 &= u_8p + u_0q = p.				
			\end{aligned}
		\end{equation*}
		Da cui, procedendo ricorsivamente e ponendo $p = 0.4$, si ottiene:
		\begin{equation*}
			u_3 = (p + pq)p = p^2(1 + q) = 0.256.
		\end{equation*}
\end{enumerate}
In conclusione, la strategia audace è più efficace.
In tal caso Mary ha una probabilità di uscire di prigione del $25.6\%$, contro il $9.64\%$ della strategia timida.
%----------------------------------------------------------------------------------------

\newpage
\section*{Esercizio 4}

\begin{problem}
	\smallskip
	Consider a DTMC with state space $S = \{0,...,N\}$ and transition probabilities $p(i, i+1) = p, p(i, i-1) = q$, for $1 \leq i \leq N$ where $p+q =1, 0 < p < 1$; assume $p(0, 0) = p(N,N-1)= q$ and $p(0, 1) = p(N,N)= p$.
	\medskip
	\begin{enumerate}[(\itshape a\normalfont)]
		\item Draw the graph (= transition diagram).
		\item Is the Markov chain irreducible?
		\item Is it aperiodic?
		\item What is the period of the chain?
		\item Find the stationary distribution.
	\end{enumerate}
	\smallskip
\end{problem}

%------------------------------------------------

\subsection*{Soluzione}

\begin{enumerate}[(\itshape a\normalfont)]
	\item Il grafo definito dalla DTMC è dato da
		\ctikzfig{fig6}
		Notiamo che tale catena è un processo di nascita e morte definito sull'intervallo $0, \dots, N$.
	\item La catena è irriducibile. Infatti $\forall i,j \in S$, come si può vedere dal grafo, esiste un cammino che congiunge i due nodi, cioé $i \leftrightarrow j$.
	\item La catena è aperiodica. Per mostrarlo ricordiamo che il periodo è una proprietà di classe, e quindi, siccome la catena è irriducibile, è uguale per tutti gli stati in $S$.
		Prendiamo lo stato $i = 0$. Questo ha un self-loop, quindi è aperiodico e di conseguenza la DTMC stessa è aperiodica.
	\item La catena è aperiodica, quindi ha periodo unitario.
	\item La catena è finita e irriducibile, quindi esiste ed è unica la distribuzione stazionaria $\pi = (\pi(i))_{i \in S}$.
		Inoltre, in quanto è un processo di nascita e morte, segue che la catena stazionaria è anche reversibile.
		Da qui si può ricavare la distribuzione stazionaria definita da
		\begin{equation*}
			\pi(0) = \frac{1}{M},	\qquad\qquad	\pi(x) = \pi(0) \left( \prod_{i=0}^{x-1} \frac{p}{q} \right) = \pi(0) \left(\frac{p}{q}\right)^x,
		\end{equation*}
		dove
		\begin{equation*}
			M = \sum_{x=0}^N \prod_{i=0}^{x-1} \left( \frac{p}{q} \right) = \sum_{x=0}^N \left(\frac{p}{q}\right)^x.
		\end{equation*}
		
	
\end{enumerate}

%------------------------------------------------
\newpage
\section*{Esercizio 5}

\begin{problem}
	\smallskip
	A rabbit runs through the maze shown below. At each step it leaves
	the room it is in by choosing at random one of the doors out of the room.
	\begin{enumerate} [(\itshape a\normalfont)]
		\item Give the transition matrix P for this Markov chain.
		\item Show that it is irreducible but not aperiodic.
		\item Find the stationary distribution.
		\item Now suppose that a carrot is placed on a deadly trap in Room
		5. The rabbit starts in Room 1. Find the expected number
		of steps before reaching Room 5 for the first time, starting in Room 1.
		\item Find the expected time to return to room 1.
	\end{enumerate}
	\smallskip
\end{problem}

%------------------------------------------------

\subsection*{Soluzione}
	\begin{enumerate}[(\itshape a\normalfont)]
	\item Osservando la figura presente nel testo dell'esercizio dato, si può rappresentare la catena attraverso il seguente grafo:
	\ctikzfig{fig7}
	Come si evince dalla consegna, il coniglio ad ogni passo sceglie a caso la stanza in cui andare tra quelle accessibili da quella in cui si trova; per cui possiamo supporre che la probabilità che il coniglio vada in una stanza vicina in un passo sia equamente distribuita tra le stanze accessibili.\\
	La matrice di transizione per questa catena di Markov è dunque la seguente:
	\begin{equation*}
		P = 
		\begin{pmatrix}
			0 & 0 & 1 & 0 & 0 & 0\\
			0 & 0 & 1 & 0 & 0 & 0\\
			1/4 & 1/4 & 0 & 1/4 & 1/4 & 0\\
			0 & 0 & 1/2 & 0 & 0 & 1/2\\
			0 & 0 & 1/2 & 0 & 0 & 1/2\\
			0 & 0 & 0 & 1/2 & 1/2 & 0
		\end{pmatrix}
	\end{equation*}
	\item La catena è irriducibile, in quanto il grafo ad essa associato è fortemente connesso, cioé 
	per ogni coppia di nodi $(i,j)$ esiste un cammino da $i$ a $j$.\\
	Se consideriamo inoltre lo stato $i = 6$, si può facilmente notare che
	\begin{equation*}
		p^{k}(i,i) > 0 \iff k = 2n : n \in \mathbb{N},
	\end{equation*}
	quindi $i$ ha periodo 2; di conseguenza, la catena non è aperiodica.
	\item Dal momento che il grafo associato a questa catena di Markov è indiretto e quindi bilanciato, la componente i-esima della distribuzione stazionaria è data da:
	\begin{equation*}
		\pi(i) = \frac{\deg(i)}{N}, \qquad\textnormal{dove }N = \sum_{j=1}^6 \deg(j)
	\end{equation*}
	La distribuzione così ottenuta, ovvero $\pi = (\frac{1}{12}, \frac{1}{12}, \frac{1}{3}, \frac{1}{6}, \frac{1}{6}, \frac{1}{6})$ è effettivamente una distribuzione stazionaria, cioé tale che $P^T \pi = \pi$. Infatti:
	\begin{equation*}
		\begin{pmatrix}
			0 & 0 & 1/4 & 0 & 0 & 0\\
			0 & 0 & 1/4 & 0 & 0 & 0\\
			1 & 1 & 0 & 1/2 & 1/2 & 0\\
			0 & 0 & 1/4 & 0 & 0 & 1/2\\
			0 & 0 & 1/4 & 0 & 0 & 1/2\\
			0 & 0 & 0 & 1/2 & 1/2 & 0
		\end{pmatrix}
		\begin{pmatrix}
			1/12 \\ 1/12 \\ 1/3 \\ 1/6 \\ 1/6 \\ 1/6
		\end{pmatrix}
		=
		\begin{pmatrix}
			1/12 \\ 1/12 \\ 1/3 \\ 1/6 \\ 1/6 \\ 1/6
		\end{pmatrix}
	\end{equation*}
	\item Consideriamo la variabile
	\begin{equation*}
		m(i) = \mathbb{E}_i [T_5] = \mathbb{E}[T_5 | X_0 = i],
	\end{equation*}
	dove $T_5$ è il tempo di primo passaggio nello stato $i$.
	Ai fini dell'esercizio, immaginiamo che il coniglio si fermi nella stanza 5 dopo esserci arrivato la prima volta, cosicché tale stato diventi ricorrente. Con questa assunzione, chiamiamo $T = \{1, 2, 3, 4, 6\}$ l'insieme degli stati transienti; procedendo con l'analisi al primo passo si ha che
	\begin{align*}
		m(i) &= 1 + \sum_{j \in T} P_{ij}m(j) \qquad \textnormal{se } i \in T \\
		m(5) &= 0
	\end{align*}
	Detto $e = (1, 1, 1, 1, 1)'$, il sistema si può riscrivere in forma matriciale:
	\begin{equation*}
		m = e + P_{T,T}m,
	\end{equation*}
	dove $P_{T,T}$ è la matrice che contiene le probabilità di passare da uno stato transiente ad un altro stato transiente.
	Quindi:
	\begin{align*}
		m(1) &= 1 + m(3)\\
		m(2) &= 1 + m(3)\\
		m(3) &= 1 + (1/4)m(1) + (1/4)m(2) + (1/4)m(4) + (1/4)m(5)\\
		m(4) &= 1 + (1/2)m(3) + (1/2)m(6)\\
		m(5) &= 0\\
		m(6) &= 1 + (1/2)m(5) + (1/2)m(4)
	\end{align*}
	La soluzione del sistema è dunque $m = (I - P_{T,T})^{-1}e$, da cui si ha in particolare che $m(1) = 7$.\\
	Inserendo questi dati su Matlab si ottiene infatti il seguente risultato:
	\begin{matlabcode}
		P_TT = [
			0, 0, 1, 0, 0;
			0, 0, 1, 0, 0;
			1/4, 1/4, 0, 1/4, 0;
			0, 0, 1/2, 0, 1/2;
			0, 0, 0, 1/2, 0]
		\end{matlabcode}
		\begin{matlaboutput}
		P_TT = 5x5    
				0         0      1.00      0      0
				0         0      1.00      0      0
				0.25      0.25   0         0.25   0
				0         0      0.50      0      0.50
				0         0      0         0.50   0
		
		\end{matlaboutput}
		\begin{matlabcode}
		n = length(P_TT);
		m = (eye(n) - P_TT) \ ones(n,1);
		m'
		\end{matlabcode}
		\begin{matlaboutput}
		ans = 1x5    
			7.0000    7.0000    6.0000    6.0000    4.0000
		
		\end{matlaboutput}
	
	Si può facilmente notare che la prima componente del vettore $m$ è effettivamente $m(1) = 7$.
	\item Per calcolare il tempo di primo ritorno allo stato 1 ci riferiamo al seguente teorema:\\
	\\
	\null\quad \textit{Se una DTMC è irriducibile ed esiste una distribuzione stazionaria $\pi$, allora
	\begin{equation*}
		\quad\pi(i) = \frac{1}{\mathbb{E}_i [T_i]}
	\end{equation*}
	\null\quad è unica, e la catena è positiva ricorrente.}\\
	\\
	Nello specifico, quindi, per questa catena di Markov si ha che $\mathbb{E}_1 [T_1] = \frac{1}{\pi(1)} = 12$.
\end{enumerate}

%------------------------------------------------

\newpage
\section*{Esercizio 6}

\begin{problem}
	\smallskip
	On his shelf, Mike keeps N books, labelled 1, 2, ..., N. Mike picks
	a book j with probability 1/N. Then Mike places it on the left of all
	others on the shelf. Mike repeats the process, independently. Construct
	a Markov chain which takes values in the set of all N! permutations of
	the books.
	\begin{enumerate}[(\itshape a\normalfont)]
		\item Discuss the state space of the Markov chain. Think how many
		elements it has and how they can be represented
		\item Show that the chain is irreducible and aperiodic and find its
		stationary distribution.		
	\end{enumerate}
	\smallskip
\end{problem}
	
%------------------------------------------------

\subsection*{Soluzione}
Definiamo lo spazio degli stati $S$ come l'insieme di tutte le possibili permutazioni degli $N$ libri sullo scaffale, dove ciascuno stato è rappresentato da un $N$-upla contenente le etichette dei libri.
La cardinalità di tale spazio degli stati $S$ è quindi data da $N!$.\\
La catena di Markov discreta può essere rappresentata attraverso un grafo diretto, costituito da:
\begin{enumerate}
	\item l'insieme dei nodi $\Upsilon$, contenente un nodo per ogni possibile permutazione dei libri sullo scaffale
	\item il set di archi $\mathcal{E}$, dove $\forall i, j \in \Upsilon$, l'arco $(i,j) \in \mathcal{E}$ se l'ordinamento dei libri relativo ai due nodi coincide a eccezione della posizione di un solo elemento,
	il quale si trova in prima posizione nella configurazione dei libri nel nodo $j$.\\
	Ad esempio, supponendo $N = 3$, l'insieme dei nodi sarà:
	\begin{align*}
		\Upsilon = \{&v_1=(1,2,3), v_2=(2,1,3), v_3=(1,3,2), \\
			&v_4=(2,3,1), v_5=(3,1,2), v_6=(3,2,1)\}
	\end{align*}
	e ogni nodo possiederà $6$ archi, di cui $3$ entranti e $3$ uscenti dal nodo. Per cui il nodo $v_1$ possiederà come archi uscenti $\{(v_1,v_1), (v_1,v_2), (v_1,v_5)\}$,
	e come archi entranti $\{(v_2,v_1), (v_4,v_1), (v_1,v_1)\}$.
	
\end{enumerate}
Osserviamo che la probabilità di estrarre un determinato libro a partire da una data configurazione è uniforme e di conseguenza la probabilità di transizione tra due stati adiacenti è $\textstyle\frac{1}{N}$.\\
Si ottiene dunque la seguente matrice di transizione P:
\begin{equation*}
	P = \begin{cases} 
		\frac{1}{N} & \textnormal{se } (i,j)\in \mathcal{E}\\
		0 & \textnormal{altrimenti}
	\end{cases}
\end{equation*}
Osserviamo che il grafo contiene un self-loop per ciascun nodo, dato dal fatto che è possibile estrarre il primo libro e reinserirlo in prima posizione mantenendo invariata la configurazione.\\
Si deduce che la catena di Markov è aperiodica poichè sono presenti dei self-loops.\\
Inoltre la catena è irriducibile, poichè $ \forall i,j \in S$ è possibile scegliere opportunamente un percorso costituito da $N$ passi, la cui probabilità $p^{(N)}(i,j)$ è strettamente positiva.\\
Costruiamo direttamente tale percorso.
Sia $i = (i_1, ... , i_N)$ un vettore che rappresenta una permutazione dei libri.
Notiamo che $p(i,j)=1/N>0$ se e solo se esiste $h\in \{1,..,N\}$ tale che $j_1 = i_h$.
Tale arco è univocamente identificato dal valore di $h$ scelto.
Possiamo quindi definire le trasformazioni lungo gli archi, le quali rappresentano un passaggio da un nodo all'altro, come $n_h(i)$.\\
Definiamo ora la variabile $I(k)$ che, ad ogni etichetta $k \in \{1,..,N\}$, associa l'indice di posizione in cui si trova il rispettivo libro.
Dunque, partendo dallo stato $i = (i_1, ... , i_N)$ è possibile giungere allo stato $j = (j_1, ... , j_N)$ tramite la seguente composizione:
\begin{equation}
	n_{I(j_1)} \circ \dots \circ n_{I(j_N)} (i)
\end{equation}
infatti si ha che tramite $n_{I(j_N)} (i)$ si ottiene il valore $h = I(j_N)$ dell'indice di posizione dell'elemento $j_N$, che viene portato in prima posizione nella configurazione successiva.\\
Procedendo in questo modo per gli $N-1$ step successivi, facciamo slittare gli elementi fino ad ottenere l elemento $j$.\\
Essendo la catena irriducibile e aperiodica, essa ammette un'unica distribuzione di probabilità stazionaria.
Osserviamo che il corrispettivo grafo è regolare poichè, per costruzione, ciascun nodo possiede lo stesso numero di archi entranti e archi uscenti.
Dato un grafo regolare con relativa matrice di transizione P, il vettore "all-ones" $\mathbf{1}$ è un autovettore della matrice $P'$ relativo all'autovalore $\lambda = 1$.
Ciò implica che $\mathbf{1}$ è una misura invariante per P. Normalizzando, si ottiene la seguente distribuzione di probabilità invariante:
\begin{equation*}
	\pi(i) = \frac{1}{N!} \quad \forall i
\end{equation*}
	
\MakeUppercase{è} possibile arrivare a tale risultato anche osservando che la matrice è doppiamente stocastica, di conseguenza la distribuzione invariante di probabilità risulta essere definita come sopra.



%----------------------------------------------------------------------------------------

\end{document}
